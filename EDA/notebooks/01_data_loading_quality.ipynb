{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMU Disturbance Analysis - Data Loading & Quality Assessment\n",
    "\n",
    "This notebook:\n",
    "1. Loads PMU and disturbance data from Excel\n",
    "2. Performs comprehensive data quality assessment\n",
    "3. Validates data integrity and linkages\n",
    "4. Saves cleaned data for subsequent analyses\n",
    "\n",
    "**Input**: `data/PMU_disturbance.xlsx` (2 sheets: PMUs, Disturbances)\n",
    "\n",
    "**Output**: `outputs/data/cleaned_data.parquet`, `outputs/reports/data_quality_report.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import project modules\n",
    "from src.data_loader import load_all_data, get_data_summary\n",
    "import config\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(config.PLOT_SETTINGS['style'])\n",
    "plt.rcParams['figure.figsize'] = config.DEFAULT_FIGSIZE\n",
    "plt.rcParams['font.size'] = config.PLOT_SETTINGS['font_size']\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "pmu_df, disturbance_df, merged_df = load_all_data(\n",
    "    config.EXCEL_FILE,\n",
    "    config.PMU_SHEET,\n",
    "    config.DISTURBANCE_SHEET\n",
    ")\n",
    "\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"PMU data shape: {pmu_df.shape}\")\n",
    "print(f\"Disturbance data shape: {disturbance_df.shape}\")\n",
    "print(f\"Merged data shape: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of PMU data\n",
    "print(\"PMU Data Sample:\")\n",
    "display(pmu_df.head())\n",
    "print(\"\\nPMU Columns:\", list(pmu_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of disturbance data\n",
    "print(\"Disturbance Data Sample:\")\n",
    "display(disturbance_df.head())\n",
    "print(\"\\nDisturbance Columns:\", list(disturbance_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values in PMU data\n",
    "pmu_missing = pd.DataFrame({\n",
    "    'Count': pmu_df.isna().sum(),\n",
    "    'Percentage': (pmu_df.isna().sum() / len(pmu_df) * 100).round(2)\n",
    "}).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values in PMU Data:\")\n",
    "display(pmu_missing[pmu_missing['Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values in disturbance data\n",
    "dist_missing = pd.DataFrame({\n",
    "    'Count': disturbance_df.isna().sum(),\n",
    "    'Percentage': (disturbance_df.isna().sum() / len(disturbance_df) * 100).round(2)\n",
    "}).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values in Disturbance Data:\")\n",
    "display(dist_missing[dist_missing['Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# PMU missing values\n",
    "pmu_missing_plot = pmu_missing[pmu_missing['Count'] > 0]\n",
    "if len(pmu_missing_plot) > 0:\n",
    "    axes[0].barh(pmu_missing_plot.index, pmu_missing_plot['Percentage'])\n",
    "    axes[0].set_xlabel('Missing Percentage (%)')\n",
    "    axes[0].set_title('Missing Values in PMU Data')\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Disturbance missing values\n",
    "dist_missing_plot = dist_missing[dist_missing['Count'] > 0]\n",
    "if len(dist_missing_plot) > 0:\n",
    "    axes[1].barh(dist_missing_plot.index, dist_missing_plot['Percentage'])\n",
    "    axes[1].set_xlabel('Missing Percentage (%)')\n",
    "    axes[1].set_title('Missing Values in Disturbance Data')\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config.FIGURE_DIR}/static/01_missing_values.png\", dpi=config.FIGURE_DPI, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "pmu_duplicates = pmu_df.duplicated().sum()\n",
    "dist_duplicates = disturbance_df.duplicated().sum()\n",
    "\n",
    "print(f\"PMU Data Duplicates: {pmu_duplicates}\")\n",
    "print(f\"Disturbance Data Duplicates: {dist_duplicates}\")\n",
    "\n",
    "if 'SectionID' in pmu_df.columns:\n",
    "    pmu_id_duplicates = pmu_df['SectionID'].duplicated().sum()\n",
    "    print(f\"Duplicate SectionIDs in PMU data: {pmu_id_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Type Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"PMU Data Types:\")\n",
    "print(pmu_df.dtypes)\n",
    "print(\"\\nDisturbance Data Types:\")\n",
    "print(disturbance_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Outlier Detection (IQR Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns for outlier detection\n",
    "numeric_cols_dist = disturbance_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Numeric columns in disturbance data: {numeric_cols_dist}\")\n",
    "\n",
    "# Calculate outliers using IQR method\n",
    "outlier_summary = {}\n",
    "for col in numeric_cols_dist:\n",
    "    Q1 = disturbance_df[col].quantile(0.25)\n",
    "    Q3 = disturbance_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = ((disturbance_df[col] < lower_bound) | (disturbance_df[col] > upper_bound)).sum()\n",
    "    outlier_summary[col] = {\n",
    "        'count': outliers,\n",
    "        'percentage': (outliers / len(disturbance_df) * 100).round(2)\n",
    "    }\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).T\n",
    "outlier_df = outlier_df[outlier_df['count'] > 0].sort_values('count', ascending=False)\n",
    "print(\"\\nOutlier Summary (IQR method):\")\n",
    "display(outlier_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Temporal Coverage Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find datetime columns\n",
    "datetime_cols = disturbance_df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "\n",
    "if datetime_cols:\n",
    "    print(\"Temporal Coverage:\")\n",
    "    for col in datetime_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Start: {disturbance_df[col].min()}\")\n",
    "        print(f\"  End: {disturbance_df[col].max()}\")\n",
    "        print(f\"  Span: {(disturbance_df[col].max() - disturbance_df[col].min()).days} days\")\n",
    "        print(f\"  Missing: {disturbance_df[col].isna().sum()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 SectionID Linkage Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate SectionID linkage\n",
    "if 'SectionID' in pmu_df.columns and 'SectionID' in disturbance_df.columns:\n",
    "    pmu_sections = set(pmu_df['SectionID'].dropna())\n",
    "    dist_sections = set(disturbance_df['SectionID'].dropna())\n",
    "    \n",
    "    print(f\"Unique SectionIDs in PMU data: {len(pmu_sections)}\")\n",
    "    print(f\"Unique SectionIDs in Disturbance data: {len(dist_sections)}\")\n",
    "    \n",
    "    # Sections in disturbances but not in PMU data\n",
    "    unmatched_sections = dist_sections - pmu_sections\n",
    "    print(f\"\\nSections in disturbances without PMU data: {len(unmatched_sections)}\")\n",
    "    if len(unmatched_sections) > 0 and len(unmatched_sections) <= 20:\n",
    "        print(f\"Unmatched sections: {sorted(unmatched_sections)}\")\n",
    "    \n",
    "    # Sections in PMU data without disturbances\n",
    "    unused_sections = pmu_sections - dist_sections\n",
    "    print(f\"\\nPMU sections without any disturbances: {len(unused_sections)}\")\n",
    "    if len(unused_sections) > 0 and len(unused_sections) <= 20:\n",
    "        print(f\"Unused sections: {sorted(unused_sections)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMU descriptive statistics\n",
    "print(\"PMU Data - Descriptive Statistics:\")\n",
    "display(pmu_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disturbance descriptive statistics\n",
    "print(\"Disturbance Data - Descriptive Statistics:\")\n",
    "display(disturbance_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive data quality report\n",
    "report_lines = []\n",
    "report_lines.append(\"=\" * 80)\n",
    "report_lines.append(\"PMU DISTURBANCE DATA QUALITY REPORT\")\n",
    "report_lines.append(\"=\" * 80)\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# Dataset overview\n",
    "report_lines.append(\"1. DATASET OVERVIEW\")\n",
    "report_lines.append(\"-\" * 80)\n",
    "report_lines.append(f\"PMU Records: {len(pmu_df):,}\")\n",
    "report_lines.append(f\"Disturbance Records: {len(disturbance_df):,}\")\n",
    "report_lines.append(f\"Merged Records: {len(merged_df):,}\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# Missing values\n",
    "report_lines.append(\"2. MISSING VALUES\")\n",
    "report_lines.append(\"-\" * 80)\n",
    "report_lines.append(\"PMU Data:\")\n",
    "pmu_missing_report = pmu_missing[pmu_missing['Count'] > 0]\n",
    "if len(pmu_missing_report) == 0:\n",
    "    report_lines.append(\"  No missing values detected\")\n",
    "else:\n",
    "    for col, row in pmu_missing_report.iterrows():\n",
    "        report_lines.append(f\"  {col}: {int(row['Count'])} ({row['Percentage']}%)\")\n",
    "        \n",
    "report_lines.append(\"\\nDisturbance Data:\")\n",
    "dist_missing_report = dist_missing[dist_missing['Count'] > 0]\n",
    "if len(dist_missing_report) == 0:\n",
    "    report_lines.append(\"  No missing values detected\")\n",
    "else:\n",
    "    for col, row in dist_missing_report.iterrows():\n",
    "        report_lines.append(f\"  {col}: {int(row['Count'])} ({row['Percentage']}%)\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# Duplicates\n",
    "report_lines.append(\"3. DUPLICATE RECORDS\")\n",
    "report_lines.append(\"-\" * 80)\n",
    "report_lines.append(f\"PMU Data: {pmu_duplicates} duplicate rows\")\n",
    "report_lines.append(f\"Disturbance Data: {dist_duplicates} duplicate rows\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# Data quality summary\n",
    "report_lines.append(\"4. DATA QUALITY SUMMARY\")\n",
    "report_lines.append(\"-\" * 80)\n",
    "report_lines.append(f\"Overall data completeness: {((1 - merged_df.isna().sum().sum() / (len(merged_df) * len(merged_df.columns))) * 100):.2f}%\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# Write report\n",
    "report_path = Path(config.REPORT_DIR) / 'data_quality_report.txt'\n",
    "report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write('\\n'.join(report_lines))\n",
    "\n",
    "print(\"Data quality report generated!\")\n",
    "print(f\"Saved to: {report_path}\")\n",
    "print(\"\\n\" + \"\\n\".join(report_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned datasets\n",
    "output_path = Path(config.CLEANED_DATA)\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save merged data as parquet for efficient storage\n",
    "merged_df.to_parquet(config.CLEANED_DATA, index=False)\n",
    "print(f\"Cleaned data saved to: {config.CLEANED_DATA}\")\n",
    "\n",
    "# Also save individual datasets as CSV for reference\n",
    "pmu_df.to_csv(Path(config.OUTPUT_DIR) / 'data' / 'pmu_data.csv', index=False)\n",
    "disturbance_df.to_csv(Path(config.OUTPUT_DIR) / 'data' / 'disturbance_data.csv', index=False)\n",
    "print(\"Individual datasets saved as CSV\")\n",
    "\n",
    "print(\"\\nData loading and quality assessment complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "- ✅ Loaded PMU and disturbance data from Excel\n",
    "- ✅ Performed comprehensive data quality assessment\n",
    "- ✅ Validated SectionID linkages\n",
    "- ✅ Generated data quality report\n",
    "- ✅ Saved cleaned data for subsequent analyses\n",
    "\n",
    "**Next Steps**: Proceed to temporal analysis (Notebook 02)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
