{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMU Disturbance Analysis - Causality & Pattern Mining\n",
    "\n",
    "This notebook analyzes disturbance causes and patterns:\n",
    "1. Cause frequency distribution and Pareto analysis\n",
    "2. Cause evolution over time\n",
    "3. Association rule mining (Apriori algorithm)\n",
    "4. Co-occurrence matrix\n",
    "5. Sequential pattern detection\n",
    "6. Reliability metrics (MTBF, MTTR, failure rates)\n",
    "7. Transition probability matrices\n",
    "\n",
    "**Input**: `outputs/data/cleaned_data.parquet`\n",
    "\n",
    "**Output**: `outputs/data/causality_results.csv`, visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import project modules\n",
    "from src import causality, visualizations as viz\n",
    "import config\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(config.PLOT_SETTINGS['style'])\n",
    "plt.rcParams['figure.figsize'] = config.DEFAULT_FIGSIZE\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "merged_df = pd.read_parquet(config.CLEANED_DATA)\n",
    "print(f\"Loaded {len(merged_df):,} records\")\n",
    "\n",
    "# Identify cause column (adjust based on your data)\n",
    "potential_cause_cols = [col for col in merged_df.columns if 'cause' in col.lower()]\n",
    "if len(potential_cause_cols) > 0:\n",
    "    cause_col = potential_cause_cols[0]\n",
    "    print(f\"Using cause column: {cause_col}\")\n",
    "else:\n",
    "    print(\"WARNING: No 'Cause' column found. Please specify manually.\")\n",
    "    cause_col = 'Cause'  # Adjust this\n",
    "\n",
    "# Identify datetime column\n",
    "datetime_cols = merged_df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "datetime_col = datetime_cols[0] if len(datetime_cols) > 0 else 'DateTime'\n",
    "print(f\"Using datetime column: {datetime_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cause Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cause distribution\n",
    "cause_dist = causality.analyze_cause_distribution(merged_df, cause_col=cause_col)\n",
    "\n",
    "print(\"Top 10 Causes by Frequency:\")\n",
    "display(cause_dist.head(10))\n",
    "\n",
    "# Pareto analysis (80/20 rule)\n",
    "pareto_causes, n_causes = causality.calculate_pareto_80_20(cause_dist)\n",
    "print(f\"\\nPareto Analysis: {n_causes} causes account for 80% of disturbances\")\n",
    "display(pareto_causes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pareto chart\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Bar chart for counts\n",
    "top_causes = cause_dist.head(15)\n",
    "x = np.arange(len(top_causes))\n",
    "ax1.bar(x, top_causes['Count'], color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Cause')\n",
    "ax1.set_ylabel('Count', color='steelblue')\n",
    "ax1.set_title('Pareto Chart: Top 15 Disturbance Causes', fontsize=14, fontweight='bold')\n",
    "ax1.tick_params(axis='y', labelcolor='steelblue')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(top_causes.index, rotation=45, ha='right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Line chart for cumulative percentage\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, top_causes['Cumulative_Percentage'], color='red', marker='o', linewidth=2)\n",
    "ax2.axhline(y=80, color='red', linestyle='--', alpha=0.5, label='80% threshold')\n",
    "ax2.set_ylabel('Cumulative Percentage (%)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "ax2.set_ylim(0, 105)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '03_01_pareto_chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cause Evolution Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cause trends over time\n",
    "merged_df['YearMonth'] = pd.to_datetime(merged_df[datetime_col]).dt.to_period('M')\n",
    "cause_evolution = merged_df.groupby(['YearMonth', cause_col]).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot top 5 causes over time\n",
    "top_5_causes = cause_dist.head(5).index.tolist()\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for cause in top_5_causes:\n",
    "    if cause in cause_evolution.columns:\n",
    "        ax.plot(cause_evolution.index.astype(str), cause_evolution[cause], marker='o', label=cause, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Year-Month')\n",
    "ax.set_ylabel('Disturbance Count')\n",
    "ax.set_title('Top 5 Causes: Evolution Over Time', fontsize=14, fontweight='bold')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '03_02_cause_evolution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mine association rules\n",
    "rules = causality.mine_association_rules(\n",
    "    merged_df,\n",
    "    cause_col=cause_col,\n",
    "    section_col='SectionID',\n",
    "    min_support=config.MIN_SUPPORT,\n",
    "    min_confidence=config.MIN_CONFIDENCE\n",
    ")\n",
    "\n",
    "if len(rules) > 0:\n",
    "    print(f\"Found {len(rules)} association rules\")\n",
    "    print(\"\\nTop 10 Association Rules:\")\n",
    "    display(rules.head(10)[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "else:\n",
    "    print(\"No association rules found. Try lowering min_support or min_confidence in config.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Co-occurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create co-occurrence matrix\n",
    "cooccurrence = causality.create_cooccurrence_matrix(\n",
    "    merged_df,\n",
    "    cause_col=cause_col,\n",
    "    section_col='SectionID'\n",
    ")\n",
    "\n",
    "# Plot heatmap for top causes\n",
    "top_10_causes = cause_dist.head(10).index.tolist()\n",
    "cooccur_subset = cooccurrence.loc[top_10_causes, top_10_causes]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(cooccur_subset, annot=True, fmt='d', cmap='YlOrRd', ax=ax, \n",
    "            cbar_kws={'label': 'Co-occurrence Count'})\n",
    "ax.set_title('Cause Co-occurrence Matrix (Top 10 Causes)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Cause')\n",
    "ax.set_ylabel('Cause')\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '03_03_cooccurrence_matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sequential Pattern Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect sequential patterns\n",
    "sequential_patterns = causality.detect_sequential_patterns(\n",
    "    merged_df,\n",
    "    datetime_col=datetime_col,\n",
    "    cause_col=cause_col,\n",
    "    section_col='SectionID',\n",
    "    window_days=config.SEQUENTIAL_WINDOW_DAYS\n",
    ")\n",
    "\n",
    "if len(sequential_patterns) > 0:\n",
    "    print(f\"Found {len(sequential_patterns)} sequential patterns\")\n",
    "    print(f\"\\nTop 10 Sequential Patterns (Cause A → Cause B within {config.SEQUENTIAL_WINDOW_DAYS} days):\")\n",
    "    display(sequential_patterns.head(10))\n",
    "else:\n",
    "    print(\"No sequential patterns found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transition Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transition matrix\n",
    "transition_matrix = causality.create_transition_matrix(\n",
    "    merged_df,\n",
    "    datetime_col=datetime_col,\n",
    "    cause_col=cause_col,\n",
    "    section_col='SectionID'\n",
    ")\n",
    "\n",
    "# Plot for top causes\n",
    "trans_subset = transition_matrix.loc[top_10_causes, top_10_causes]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(trans_subset, annot=True, fmt='.2f', cmap='Blues', ax=ax,\n",
    "            cbar_kws={'label': 'Transition Probability'})\n",
    "ax.set_title('Transition Probability Matrix: P(Cause B | Cause A)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Next Cause (B)')\n",
    "ax.set_ylabel('Current Cause (A)')\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '03_04_transition_matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reliability Metrics (MTBF, MTTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MTBF and MTTR\n",
    "reliability_metrics = causality.calculate_mtbf_mttr(\n",
    "    merged_df,\n",
    "    datetime_col=datetime_col,\n",
    "    section_col='SectionID'\n",
    ")\n",
    "\n",
    "print(\"Reliability Metrics by Section:\")\n",
    "print(\"\\nTop 10 sections by failure count:\")\n",
    "display(reliability_metrics.head(10))\n",
    "\n",
    "print(\"\\nOverall Statistics:\")\n",
    "print(f\"  Mean MTBF: {reliability_metrics['MTBF_hours'].mean():.2f} hours\")\n",
    "print(f\"  Median MTBF: {reliability_metrics['MTBF_hours'].median():.2f} hours\")\n",
    "print(f\"  Mean Failure Rate: {reliability_metrics['Failure_Rate'].mean():.6f} failures/hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MTBF distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# MTBF histogram\n",
    "mtbf_values = reliability_metrics['MTBF_hours'].dropna()\n",
    "axes[0].hist(mtbf_values, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].set_xlabel('MTBF (hours)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Mean Time Between Failures')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Failure count vs MTBF\n",
    "axes[1].scatter(reliability_metrics['Failure_Count'], reliability_metrics['MTBF_hours'], alpha=0.6)\n",
    "axes[1].set_xlabel('Number of Failures')\n",
    "axes[1].set_ylabel('MTBF (hours)')\n",
    "axes[1].set_title('Failure Count vs MTBF')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '03_05_mtbf_analysis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cause Severity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cause severity\n",
    "# Note: This uses Operations column if available in your data\n",
    "operations_cols = [col for col in merged_df.columns if 'operation' in col.lower()]\n",
    "operations_col = operations_cols[0] if len(operations_cols) > 0 else None\n",
    "\n",
    "severity = causality.calculate_cause_severity(\n",
    "    merged_df,\n",
    "    cause_col=cause_col,\n",
    "    operations_col=operations_col\n",
    ")\n",
    "\n",
    "print(\"Cause Severity Analysis:\")\n",
    "display(severity.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sankey Diagram (Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sankey diagram showing cause transitions\n",
    "if len(sequential_patterns) > 0:\n",
    "    # Get top 20 sequential patterns\n",
    "    top_patterns = sequential_patterns.head(20)\n",
    "    \n",
    "    # Create unique node list\n",
    "    all_causes = list(set(top_patterns['From'].tolist() + top_patterns['To'].tolist()))\n",
    "    cause_to_idx = {cause: i for i, cause in enumerate(all_causes)}\n",
    "    \n",
    "    # Create Sankey data\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=20,\n",
    "            label=all_causes\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=[cause_to_idx[f] for f in top_patterns['From']],\n",
    "            target=[cause_to_idx[t] for t in top_patterns['To']],\n",
    "            value=top_patterns['Count'].tolist()\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Sequential Cause Patterns (Sankey Diagram)',\n",
    "        font_size=10,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    viz.save_figure(fig, '03_06_sankey_diagram', static=False, interactive=True)\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No sequential patterns available for Sankey diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save main results\n",
    "cause_dist.to_csv(config.CAUSALITY_RESULTS, index=True)\n",
    "print(f\"Cause distribution saved to: {config.CAUSALITY_RESULTS}\")\n",
    "\n",
    "# Save reliability metrics\n",
    "reliability_path = Path(config.OUTPUT_DIR) / 'data' / 'reliability_metrics.csv'\n",
    "reliability_metrics.to_csv(reliability_path, index=False)\n",
    "print(f\"Reliability metrics saved to: {reliability_path}\")\n",
    "\n",
    "# Save sequential patterns if found\n",
    "if len(sequential_patterns) > 0:\n",
    "    patterns_path = Path(config.OUTPUT_DIR) / 'data' / 'sequential_patterns.csv'\n",
    "    sequential_patterns.to_csv(patterns_path, index=False)\n",
    "    print(f\"Sequential patterns saved to: {patterns_path}\")\n",
    "\n",
    "print(\"\\nCausality analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "- ✅ Analyzed cause frequency distribution and Pareto principle\n",
    "- ✅ Examined cause evolution over time\n",
    "- ✅ Mined association rules between causes\n",
    "- ✅ Created co-occurrence and transition matrices\n",
    "- ✅ Detected sequential patterns\n",
    "- ✅ Calculated reliability metrics (MTBF, MTTR, failure rates)\n",
    "- ✅ Generated 6 visualizations including Sankey diagram\n",
    "\n",
    "**Key Findings**: Review the outputs above for causality insights\n",
    "\n",
    "**Next Steps**: Proceed to Notebook 04 (Spatial & Network Analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
