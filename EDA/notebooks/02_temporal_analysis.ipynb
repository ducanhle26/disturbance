{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMU Disturbance Analysis - Temporal Analysis\n",
    "\n",
    "This notebook performs comprehensive temporal analysis including:\n",
    "1. Time series decomposition (STL)\n",
    "2. Anomaly detection (3 methods)\n",
    "3. Inter-arrival time analysis\n",
    "4. Change point detection\n",
    "5. Cyclical patterns (hourly, daily, monthly)\n",
    "6. Rolling statistics and trend analysis\n",
    "7. ACF/PACF analysis\n",
    "\n",
    "**Input**: `outputs/data/cleaned_data.parquet` (from Notebook 01)\n",
    "\n",
    "**Output**: `outputs/data/temporal_results.csv`, visualizations, insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import project modules\n",
    "from src import temporal, visualizations as viz\n",
    "import config\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(config.PLOT_SETTINGS['style'])\n",
    "plt.rcParams['figure.figsize'] = config.DEFAULT_FIGSIZE\n",
    "plt.rcParams['font.size'] = config.PLOT_SETTINGS['font_size']\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data from Notebook 01\n",
    "merged_df = pd.read_parquet(config.CLEANED_DATA)\n",
    "print(f\"Loaded {len(merged_df):,} records\")\n",
    "print(f\"Columns: {list(merged_df.columns)}\")\n",
    "\n",
    "# Identify datetime column (adjust based on your actual data)\n",
    "datetime_cols = merged_df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "if len(datetime_cols) > 0:\n",
    "    datetime_col = datetime_cols[0]\n",
    "    print(f\"\\nUsing datetime column: {datetime_col}\")\n",
    "else:\n",
    "    print(\"\\nWARNING: No datetime column found. Please specify manually.\")\n",
    "    datetime_col = 'DateTime'  # Adjust this to match your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate disturbances by day\n",
    "daily_counts = temporal.aggregate_disturbances_by_time(\n",
    "    merged_df, \n",
    "    datetime_col=datetime_col, \n",
    "    freq='D'\n",
    ")\n",
    "\n",
    "print(f\"Daily time series:\")\n",
    "print(f\"  Date range: {daily_counts.index.min()} to {daily_counts.index.max()}\")\n",
    "print(f\"  Total days: {len(daily_counts)}\")\n",
    "print(f\"  Mean daily disturbances: {daily_counts.mean():.2f}\")\n",
    "print(f\"  Std daily disturbances: {daily_counts.std():.2f}\")\n",
    "print(f\"  Max daily disturbances: {daily_counts.max()}\")\n",
    "\n",
    "# Plot raw time series\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(daily_counts.index, daily_counts.values, linewidth=1.5, color='steelblue')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Daily Disturbance Count')\n",
    "ax.set_title('PMU Disturbances Over Time', fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '02_01_daily_time_series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time Series Decomposition (STL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform STL decomposition\n",
    "decomposition = temporal.decompose_time_series(daily_counts, period=7)\n",
    "\n",
    "# Plot decomposition (static)\n",
    "fig = viz.plot_time_series_decomposition(\n",
    "    decomposition,\n",
    "    title='STL Decomposition of Daily Disturbances',\n",
    "    interactive=False\n",
    ")\n",
    "viz.save_figure(fig, '02_02_stl_decomposition')\n",
    "plt.show()\n",
    "\n",
    "# Plot decomposition (interactive)\n",
    "fig_interactive = viz.plot_time_series_decomposition(\n",
    "    decomposition,\n",
    "    title='STL Decomposition of Daily Disturbances (Interactive)',\n",
    "    interactive=True\n",
    ")\n",
    "viz.save_figure(fig_interactive, '02_02_stl_decomposition', static=False, interactive=True)\n",
    "fig_interactive.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies using three methods\n",
    "anomalies_zscore = temporal.detect_anomalies_zscore(daily_counts, threshold=3.0)\n",
    "anomalies_iqr = temporal.detect_anomalies_iqr(daily_counts, multiplier=1.5)\n",
    "anomalies_iforest = temporal.detect_anomalies_isolation_forest(daily_counts, contamination=0.1)\n",
    "\n",
    "print(\"Anomaly Detection Results:\")\n",
    "print(f\"  Z-score (threshold=3.0): {anomalies_zscore.sum()} anomalies detected\")\n",
    "print(f\"  IQR (multiplier=1.5): {anomalies_iqr.sum()} anomalies detected\")\n",
    "print(f\"  Isolation Forest (contamination=0.1): {anomalies_iforest.sum()} anomalies detected\")\n",
    "\n",
    "# Plot anomalies (static)\n",
    "anomalies_dict = {\n",
    "    'Z-score': anomalies_zscore,\n",
    "    'IQR': anomalies_iqr,\n",
    "    'Isolation Forest': anomalies_iforest\n",
    "}\n",
    "\n",
    "fig = viz.plot_anomalies(\n",
    "    daily_counts,\n",
    "    anomalies_dict,\n",
    "    title='Anomaly Detection: Daily Disturbances',\n",
    "    interactive=False\n",
    ")\n",
    "viz.save_figure(fig, '02_03_anomaly_detection')\n",
    "plt.show()\n",
    "\n",
    "# Plot anomalies (interactive)\n",
    "fig_interactive = viz.plot_anomalies(\n",
    "    daily_counts,\n",
    "    anomalies_dict,\n",
    "    title='Anomaly Detection: Daily Disturbances (Interactive)',\n",
    "    interactive=True\n",
    ")\n",
    "viz.save_figure(fig_interactive, '02_03_anomaly_detection', static=False, interactive=True)\n",
    "fig_interactive.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inter-Arrival Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inter-arrival times\n",
    "df_with_intervals = temporal.calculate_inter_arrival_times(\n",
    "    merged_df,\n",
    "    datetime_col=datetime_col,\n",
    "    group_by='SectionID'\n",
    ")\n",
    "\n",
    "inter_arrival = df_with_intervals['inter_arrival_hours'].dropna()\n",
    "\n",
    "print(f\"Inter-Arrival Time Statistics:\")\n",
    "print(f\"  Mean: {inter_arrival.mean():.2f} hours\")\n",
    "print(f\"  Median: {inter_arrival.median():.2f} hours\")\n",
    "print(f\"  Std: {inter_arrival.std():.2f} hours\")\n",
    "print(f\"  Min: {inter_arrival.min():.2f} hours\")\n",
    "print(f\"  Max: {inter_arrival.max():.2f} hours\")\n",
    "\n",
    "# Test for Poisson process\n",
    "poisson_test = temporal.test_poisson_process(inter_arrival, alpha=0.05)\n",
    "print(f\"\\nPoisson Process Test:\")\n",
    "if 'error' not in poisson_test:\n",
    "    print(f\"  Conclusion: {poisson_test['conclusion']}\")\n",
    "    print(f\"  P-value: {poisson_test['p_value']:.4f}\")\n",
    "    print(f\"  Mean inter-arrival: {poisson_test['mean_inter_arrival']:.2f} hours\")\n",
    "else:\n",
    "    print(f\"  Error: {poisson_test['error']}\")\n",
    "\n",
    "# Plot inter-arrival time distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(inter_arrival, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Inter-Arrival Time (hours)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Inter-Arrival Times')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(inter_arrival, vert=True)\n",
    "axes[1].set_ylabel('Inter-Arrival Time (hours)')\n",
    "axes[1].set_title('Inter-Arrival Time Box Plot')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '02_04_inter_arrival_times')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Change Point Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect change points\n",
    "change_points = temporal.detect_change_points(\n",
    "    daily_counts,\n",
    "    model='rbf',\n",
    "    min_size=7,\n",
    "    jump=5,\n",
    "    pen=3\n",
    ")\n",
    "\n",
    "print(f\"Change Point Detection:\")\n",
    "print(f\"  Number of change points detected: {len(change_points)}\")\n",
    "if len(change_points) > 0:\n",
    "    change_dates = [daily_counts.index[cp] for cp in change_points if cp < len(daily_counts)]\n",
    "    print(f\"  Change point dates: {change_dates}\")\n",
    "\n",
    "# Plot time series with change points\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(daily_counts.index, daily_counts.values, linewidth=1.5, color='steelblue', label='Daily Counts')\n",
    "\n",
    "# Mark change points\n",
    "for cp in change_points:\n",
    "    if cp < len(daily_counts):\n",
    "        ax.axvline(daily_counts.index[cp], color='red', linestyle='--', alpha=0.7, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Daily Disturbance Count')\n",
    "ax.set_title(f'Change Point Detection ({len(change_points)} points detected)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '02_05_change_points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling statistics\n",
    "rolling_stats = temporal.calculate_rolling_statistics(\n",
    "    daily_counts,\n",
    "    windows=config.ROLLING_WINDOWS\n",
    ")\n",
    "\n",
    "print(\"Rolling Statistics Calculated:\")\n",
    "print(rolling_stats.head())\n",
    "\n",
    "# Plot rolling statistics (static)\n",
    "fig = viz.plot_rolling_statistics(\n",
    "    rolling_stats,\n",
    "    title='Rolling Statistics: Daily Disturbances',\n",
    "    interactive=False\n",
    ")\n",
    "viz.save_figure(fig, '02_06_rolling_statistics')\n",
    "plt.show()\n",
    "\n",
    "# Plot rolling statistics (interactive)\n",
    "fig_interactive = viz.plot_rolling_statistics(\n",
    "    rolling_stats,\n",
    "    title='Rolling Statistics: Daily Disturbances (Interactive)',\n",
    "    interactive=True\n",
    ")\n",
    "viz.save_figure(fig_interactive, '02_06_rolling_statistics', static=False, interactive=True)\n",
    "fig_interactive.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cyclical Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cyclical patterns\n",
    "patterns = temporal.extract_cyclical_patterns(merged_df, datetime_col=datetime_col)\n",
    "\n",
    "print(\"Cyclical Pattern Analysis:\")\n",
    "print(f\"\\nHourly Pattern (top 5 hours):\")\n",
    "print(patterns['hourly'].sort_values(ascending=False).head())\n",
    "print(f\"\\nDaily Pattern:\")\n",
    "print(patterns['daily'])\n",
    "print(f\"\\nWeekend vs Weekday:\")\n",
    "print(patterns['weekend_vs_weekday'])\n",
    "\n",
    "# Plot cyclical patterns (static)\n",
    "fig = viz.plot_cyclical_patterns(\n",
    "    patterns,\n",
    "    title='Cyclical Patterns in PMU Disturbances',\n",
    "    interactive=False\n",
    ")\n",
    "viz.save_figure(fig, '02_07_cyclical_patterns')\n",
    "plt.show()\n",
    "\n",
    "# Plot cyclical patterns (interactive)\n",
    "fig_interactive = viz.plot_cyclical_patterns(\n",
    "    patterns,\n",
    "    title='Cyclical Patterns in PMU Disturbances (Interactive)',\n",
    "    interactive=True\n",
    ")\n",
    "viz.save_figure(fig_interactive, '02_07_cyclical_patterns', static=False, interactive=True)\n",
    "fig_interactive.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calendar Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create calendar heatmap (interactive only)\n",
    "fig = viz.plot_calendar_heatmap(\n",
    "    merged_df,\n",
    "    datetime_col=datetime_col,\n",
    "    title='PMU Disturbance Calendar Heatmap'\n",
    ")\n",
    "viz.save_figure(fig, '02_08_calendar_heatmap', static=False, interactive=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ACF and PACF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ACF and PACF\n",
    "acf_values, pacf_values = temporal.calculate_acf_pacf(daily_counts, nlags=40)\n",
    "\n",
    "# Plot ACF and PACF\n",
    "fig = viz.plot_acf_pacf(\n",
    "    acf_values,\n",
    "    pacf_values,\n",
    "    title='Autocorrelation and Partial Autocorrelation Functions'\n",
    ")\n",
    "viz.save_figure(fig, '02_09_acf_pacf')\n",
    "plt.show()\n",
    "\n",
    "print(\"ACF and PACF Analysis:\")\n",
    "print(f\"  First 5 ACF values: {acf_values[:5]}\")\n",
    "print(f\"  First 5 PACF values: {pacf_values[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile temporal analysis results\n",
    "temporal_results = pd.DataFrame({\n",
    "    'Analysis': ['Time Series Stats', 'Anomalies (Z-score)', 'Anomalies (IQR)', \n",
    "                 'Anomalies (IForest)', 'Change Points', 'Mean Inter-Arrival (hrs)'],\n",
    "    'Value': [\n",
    "        f\"Mean: {daily_counts.mean():.2f}, Std: {daily_counts.std():.2f}\",\n",
    "        anomalies_zscore.sum(),\n",
    "        anomalies_iqr.sum(),\n",
    "        anomalies_iforest.sum(),\n",
    "        len(change_points),\n",
    "        f\"{inter_arrival.mean():.2f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "temporal_results.to_csv(config.TEMPORAL_RESULTS, index=False)\n",
    "print(f\"\\nTemporal analysis results saved to: {config.TEMPORAL_RESULTS}\")\n",
    "print(\"\\nResults Summary:\")\n",
    "display(temporal_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "- ✅ Decomposed time series into trend, seasonal, and residual components\n",
    "- ✅ Detected anomalies using 3 different methods\n",
    "- ✅ Analyzed inter-arrival times and tested for Poisson process\n",
    "- ✅ Identified change points in disturbance rates\n",
    "- ✅ Examined cyclical patterns (hourly, daily, monthly)\n",
    "- ✅ Calculated rolling statistics for trend analysis\n",
    "- ✅ Performed ACF/PACF analysis\n",
    "- ✅ Generated 9 visualizations (both static and interactive)\n",
    "\n",
    "**Key Findings**: Review the outputs above for temporal insights\n",
    "\n",
    "**Next Steps**: Proceed to Notebook 03 (Causality & Pattern Mining)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
