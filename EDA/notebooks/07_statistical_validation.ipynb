{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMU Disturbance Analysis - Statistical Validation\n",
    "\n",
    "Hypothesis testing, distribution fitting, and correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import statistical, temporal, visualizations as viz\n",
    "import config\n",
    "\n",
    "sns.set_style(config.PLOT_SETTINGS['style'])\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_parquet(config.CLEANED_DATA)\n",
    "pmu_df = pd.read_csv(Path(config.OUTPUT_DIR) / 'data' / 'pmu_data.csv')\n",
    "\n",
    "datetime_cols = merged_df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "datetime_col = datetime_cols[0] if datetime_cols else 'DateTime'\n",
    "print(f\"Data loaded. Using datetime column: {datetime_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distribution Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate daily counts\n",
    "daily_counts = temporal.aggregate_disturbances_by_time(merged_df, datetime_col, freq='D')\n",
    "\n",
    "# Test distribution fit\n",
    "distribution_tests = statistical.test_distribution_fit(\n",
    "    daily_counts,\n",
    "    distributions=['poisson', 'nbinom', 'norm']\n",
    ")\n",
    "\n",
    "print(\"Distribution Fitting Results:\")\n",
    "display(distribution_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plot for normal distribution\n",
    "from scipy import stats as sp_stats\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sp_stats.probplot(daily_counts, dist=\"norm\", plot=ax)\n",
    "ax.set_title('Q-Q Plot: Daily Disturbance Counts vs Normal Distribution', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "viz.save_figure(fig, '07_01_qq_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mann-Kendall Trend Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for trend\n",
    "mk_result = statistical.mann_kendall_test(daily_counts)\n",
    "\n",
    "print(\"Mann-Kendall Trend Test:\")\n",
    "if 'error' not in mk_result:\n",
    "    for key, value in mk_result.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(f\"  Error: {mk_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for correlation\n",
    "numeric_cols = merged_df.select_dtypes(include=[np.number]).columns.tolist()[:10]  # Limit to first 10\n",
    "\n",
    "if len(numeric_cols) > 1:\n",
    "    corr_matrix, p_values = statistical.correlation_analysis(\n",
    "        merged_df, \n",
    "        columns=numeric_cols,\n",
    "        method='spearman'\n",
    "    )\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Create significance mask\n",
    "    mask = p_values > 0.05\n",
    "    \n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, vmin=-1, vmax=1, ax=ax,\n",
    "                mask=mask, cbar_kws={'label': 'Spearman Correlation'})\n",
    "    ax.set_title('Correlation Matrix (Significant Correlations Only, p<0.05)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    viz.save_figure(fig, '07_02_correlation_matrix')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient numeric columns for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Voltage Level vs Disturbance Test (ANOVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if voltage level affects disturbance rates\n",
    "voltage_cols = [c for c in pmu_df.columns if 'voltage' in c.lower()]\n",
    "\n",
    "if voltage_cols:\n",
    "    voltage_col = voltage_cols[0]\n",
    "    \n",
    "    # Merge disturbance counts with PMU voltage\n",
    "    disturbance_counts = merged_df.groupby('SectionID').size().reset_index(name='DisturbanceCount')\n",
    "    pmu_with_counts = pmu_df.merge(disturbance_counts, on='SectionID', how='left')\n",
    "    pmu_with_counts['DisturbanceCount'] = pmu_with_counts['DisturbanceCount'].fillna(0)\n",
    "    \n",
    "    # Perform ANOVA\n",
    "    anova_result = statistical.test_voltage_disturbance_relationship(\n",
    "        pmu_with_counts,\n",
    "        voltage_col=voltage_col,\n",
    "        disturbance_count_col='DisturbanceCount'\n",
    "    )\n",
    "    \n",
    "    print(\"ANOVA: Voltage Level vs Disturbance Rate\")\n",
    "    if 'error' not in anova_result:\n",
    "        for key, value in anova_result.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  Error: {anova_result['error']}\")\n",
    "else:\n",
    "    print(\"No voltage column found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bootstrap Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bootstrap CIs for key metrics\n",
    "metrics = ['mean', 'median', 'std']\n",
    "bootstrap_results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    result = statistical.bootstrap_confidence_interval(\n",
    "        daily_counts,\n",
    "        statistic=metric,\n",
    "        n_bootstrap=1000,\n",
    "        confidence_level=config.CONFIDENCE_LEVEL\n",
    "    )\n",
    "    bootstrap_results.append(result)\n",
    "    \n",
    "print(\"Bootstrap Confidence Intervals (95%):\")\n",
    "for result in bootstrap_results:\n",
    "    if 'error' not in result:\n",
    "        print(f\"  {result['Statistic']}: {result['Point_Estimate']:.2f} \"\n",
    "              f\"[{result['CI_Lower']:.2f}, {result['CI_Upper']:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chi-Square Independence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test independence between categorical variables\n",
    "cause_cols = [c for c in merged_df.columns if 'cause' in c.lower()]\n",
    "type_cols = [c for c in merged_df.columns if 'type' in c.lower()]\n",
    "\n",
    "if cause_cols and type_cols:\n",
    "    chi2_result = statistical.chi_square_independence_test(\n",
    "        merged_df,\n",
    "        col1=cause_cols[0],\n",
    "        col2=type_cols[0]\n",
    "    )\n",
    "    \n",
    "    print(\"Chi-Square Independence Test:\")\n",
    "    print(f\"  {chi2_result['Interpretation']}\")\n",
    "    print(f\"  Chi2 Statistic: {chi2_result['Chi2_Statistic']:.2f}\")\n",
    "    print(f\"  P-value: {chi2_result['P_Value']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile statistical validation results\n",
    "validation_results = pd.DataFrame({\n",
    "    'Test': ['Distribution Fit (Best)', 'Mann-Kendall Trend', 'Bootstrap CI Mean'],\n",
    "    'Result': [\n",
    "        distribution_tests.iloc[0]['Distribution'] if len(distribution_tests) > 0 else 'N/A',\n",
    "        mk_result.get('Trend', 'Error'),\n",
    "        f\"{bootstrap_results[0]['Point_Estimate']:.2f} [{bootstrap_results[0]['CI_Lower']:.2f}, {bootstrap_results[0]['CI_Upper']:.2f}]\" if bootstrap_results else 'N/A'\n",
    "    ]\n",
    "})\n",
    "\n",
    "validation_results.to_csv(config.STATISTICAL_RESULTS, index=False)\n",
    "print(f\"\\nStatistical validation results saved to: {config.STATISTICAL_RESULTS}\")\n",
    "display(validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- ✅ Tested distribution fits (Poisson, Negative Binomial, Normal)\n",
    "- ✅ Performed Mann-Kendall trend test\n",
    "- ✅ Calculated correlation matrix with significance testing\n",
    "- ✅ Tested voltage-disturbance relationship (ANOVA)\n",
    "- ✅ Generated bootstrap confidence intervals\n",
    "- ✅ Performed chi-square independence tests\n",
    "\n",
    "**Analysis Complete!** All 7 notebooks executed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
