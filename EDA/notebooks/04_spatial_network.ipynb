{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMU Disturbance Analysis - Spatial & Network Analysis\n",
    "\n",
    "Geographic clustering, spatial statistics, and network topology analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import folium\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import spatial, visualizations as viz\n",
    "import config\n",
    "\n",
    "sns.set_style(config.PLOT_SETTINGS['style'])\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data & Validate Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_parquet(config.CLEANED_DATA)\n",
    "pmu_df = pd.read_csv(Path(config.OUTPUT_DIR) / 'data' / 'pmu_data.csv')\n",
    "\n",
    "# Identify coordinate columns\n",
    "lat_col = [c for c in pmu_df.columns if 'lat' in c.lower()]\n",
    "lon_col = [c for c in pmu_df.columns if 'lon' in c.lower()]\n",
    "lat_col = lat_col[0] if lat_col else 'Latitude'\n",
    "lon_col = lon_col[0] if lon_col else 'Longitude'\n",
    "\n",
    "# Validate coordinates\n",
    "validation = spatial.validate_coordinates(pmu_df, lat_col, lon_col)\n",
    "print(\"Coordinate Validation:\")\n",
    "for key, value in validation.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geographic Clustering (DBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform DBSCAN clustering\n",
    "pmu_clustered = spatial.perform_dbscan_clustering(\n",
    "    pmu_df, lat_col, lon_col,\n",
    "    eps=config.DBSCAN_EPS,\n",
    "    min_samples=config.DBSCAN_MIN_SAMPLES\n",
    ")\n",
    "\n",
    "print(f\"Clusters found: {pmu_clustered['Cluster'].nunique()}\")\n",
    "print(pmu_clustered['Cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Map with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive map\n",
    "if validation['valid_coordinates'] > 0:\n",
    "    valid_data = pmu_clustered[[lat_col, lon_col, 'Cluster']].dropna()\n",
    "    center_lat = valid_data[lat_col].mean()\n",
    "    center_lon = valid_data[lon_col].mean()\n",
    "    \n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=10)\n",
    "    \n",
    "    # Add markers\n",
    "    colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred', 'beige', 'darkblue', 'darkgreen']\n",
    "    for idx, row in valid_data.iterrows():\n",
    "        cluster = int(row['Cluster']) if row['Cluster'] >= 0 else -1\n",
    "        color = colors[cluster % len(colors)] if cluster >= 0 else 'gray'\n",
    "        folium.CircleMarker(\n",
    "            location=[row[lat_col], row[lon_col]],\n",
    "            radius=5,\n",
    "            popup=f\"Cluster: {cluster}\",\n",
    "            color=color,\n",
    "            fill=True\n",
    "        ).add_to(m)\n",
    "    \n",
    "    map_path = Path(config.FIGURE_DIR) / 'interactive' / '04_01_pmu_locations_map.html'\n",
    "    m.save(str(map_path))\n",
    "    print(f\"Map saved to: {map_path}\")\n",
    "    display(m)\n",
    "else:\n",
    "    print(\"No valid coordinates for mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial Autocorrelation (Moran's I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate disturbance counts per section\n",
    "section_counts = merged_df.groupby('SectionID').size().reset_index(name='DisturbanceCount')\n",
    "pmu_with_counts = pmu_df.merge(section_counts, on='SectionID', how='left')\n",
    "pmu_with_counts['DisturbanceCount'] = pmu_with_counts['DisturbanceCount'].fillna(0)\n",
    "\n",
    "# Calculate Moran's I\n",
    "morans_result = spatial.calculate_morans_i(\n",
    "    pmu_with_counts,\n",
    "    value_col='DisturbanceCount',\n",
    "    lat_col=lat_col,\n",
    "    lon_col=lon_col,\n",
    "    threshold_distance=1.0\n",
    ")\n",
    "\n",
    "print(\"Moran's I Spatial Autocorrelation Test:\")\n",
    "if 'error' not in morans_result:\n",
    "    for key, value in morans_result.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(f\"  Error: {morans_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build proximity network\n",
    "G = spatial.build_proximity_network(\n",
    "    pmu_df, lat_col, lon_col,\n",
    "    id_col='SectionID',\n",
    "    threshold_distance=1.0\n",
    ")\n",
    "\n",
    "print(f\"Network Statistics:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")\n",
    "print(f\"  Density: {2 * G.number_of_edges() / (G.number_of_nodes() * (G.number_of_nodes() - 1)):.4f}\")\n",
    "\n",
    "# Calculate centrality\n",
    "centrality = spatial.calculate_network_centrality(G)\n",
    "print(\"\\nTop 10 nodes by betweenness centrality:\")\n",
    "display(centrality.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save spatial results\n",
    "spatial_results = pd.DataFrame({\n",
    "    'Metric': ['Num_Clusters', 'Valid_Coordinates', 'Morans_I', 'Network_Nodes', 'Network_Edges'],\n",
    "    'Value': [\n",
    "        pmu_clustered['Cluster'].nunique(),\n",
    "        validation['valid_coordinates'],\n",
    "        morans_result.get('Morans_I', np.nan),\n",
    "        G.number_of_nodes(),\n",
    "        G.number_of_edges()\n",
    "    ]\n",
    "})\n",
    "\n",
    "spatial_results.to_csv(config.SPATIAL_RESULTS, index=False)\n",
    "print(f\"Spatial results saved to: {config.SPATIAL_RESULTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Completed spatial and network analysis.\n",
    "\n",
    "**Next**: Notebook 05 (Predictive Modeling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
