{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Risk Scoring Framework\n",
    "\n",
    "This notebook demonstrates the multi-dimensional risk scoring methodology.\n",
    "\n",
    "**Risk Components:**\n",
    "1. **Frequency** (35%): Historical event count\n",
    "2. **Trend** (25%): Are events increasing over time?\n",
    "3. **MTBF** (20%): Mean time between failures (inverted)\n",
    "4. **Age** (10%): Equipment age\n",
    "5. **Recency** (10%): Time since last event (inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_loader import load_pmu_disturbance_data\n",
    "from risk_scorer import PMURiskScorer\n",
    "\n",
    "DATA_PATH = '../../data/PMU_disturbance.xlsx'\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmu_df, dist_df = load_pmu_disturbance_data(DATA_PATH)\n",
    "print(f\"Loaded {len(pmu_df)} PMUs and {len(dist_df)} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Risk Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default weights\n",
    "default_weights = {\n",
    "    'frequency': 0.35,\n",
    "    'trend': 0.25,\n",
    "    'mtbf': 0.20,\n",
    "    'age': 0.10,\n",
    "    'recency': 0.10\n",
    "}\n",
    "\n",
    "scorer = PMURiskScorer(pmu_df, dist_df, weights=default_weights)\n",
    "results = scorer.calculate_risk_scores()\n",
    "\n",
    "print(f\"Calculated risk scores for {len(results)} sections\")\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(results['risk_score'], bins=30, color='steelblue', edgecolor='white')\n",
    "axes[0].axvline(results['risk_score'].mean(), color='red', linestyle='--', label=f'Mean: {results[\"risk_score\"].mean():.1f}')\n",
    "axes[0].set_xlabel('Risk Score')\n",
    "axes[0].set_ylabel('Number of Sections')\n",
    "axes[0].set_title('Risk Score Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Category counts\n",
    "category_counts = results['category'].value_counts()\n",
    "colors = {'Low': 'green', 'Medium': 'orange', 'High': 'red'}\n",
    "axes[1].bar(category_counts.index, category_counts.values, color=[colors.get(c, 'gray') for c in category_counts.index])\n",
    "axes[1].set_xlabel('Risk Category')\n",
    "axes[1].set_ylabel('Number of Sections')\n",
    "axes[1].set_title('Risk Category Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get component scores for top 10 sections\n",
    "top_10 = results.head(10)\n",
    "\n",
    "component_cols = [c for c in results.columns if c.endswith('_score') and c != 'risk_score']\n",
    "if component_cols:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    x = np.arange(len(top_10))\n",
    "    width = 0.15\n",
    "    \n",
    "    for i, col in enumerate(component_cols):\n",
    "        ax.bar(x + i*width, top_10[col], width, label=col.replace('_score', ''))\n",
    "    \n",
    "    ax.set_xlabel('Section')\n",
    "    ax.set_ylabel('Component Score')\n",
    "    ax.set_title('Risk Component Breakdown - Top 10 Sections')\n",
    "    ax.set_xticks(x + width * 2)\n",
    "    ax.set_xticklabels([f\"S{int(s)}\" for s in top_10['SectionID']])\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Component scores not available in results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Weight Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different weight configurations\n",
    "weight_configs = {\n",
    "    'Default': {'frequency': 0.35, 'trend': 0.25, 'mtbf': 0.20, 'age': 0.10, 'recency': 0.10},\n",
    "    'Frequency-Heavy': {'frequency': 0.60, 'trend': 0.15, 'mtbf': 0.10, 'age': 0.10, 'recency': 0.05},\n",
    "    'Trend-Heavy': {'frequency': 0.20, 'trend': 0.50, 'mtbf': 0.15, 'age': 0.10, 'recency': 0.05},\n",
    "    'Balanced': {'frequency': 0.20, 'trend': 0.20, 'mtbf': 0.20, 'age': 0.20, 'recency': 0.20}\n",
    "}\n",
    "\n",
    "rankings = {}\n",
    "for name, weights in weight_configs.items():\n",
    "    scorer = PMURiskScorer(pmu_df, dist_df, weights=weights)\n",
    "    r = scorer.calculate_risk_scores()\n",
    "    rankings[name] = r.head(10)['SectionID'].tolist()\n",
    "\n",
    "print(\"Top 10 Rankings by Weight Configuration:\")\n",
    "for name, top_10 in rankings.items():\n",
    "    print(f\"\\n{name}: {top_10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Between Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "score_cols = ['risk_score'] + [c for c in results.columns if c.endswith('_score') and c != 'risk_score']\n",
    "if len(score_cols) > 1:\n",
    "    corr = results[score_cols].corr()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', center=0, ax=ax)\n",
    "    ax.set_title('Component Score Correlations')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient component scores for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The multi-dimensional risk scoring framework:\n",
    "- Combines 5 risk factors with configurable weights\n",
    "- Section 150 consistently ranks #1 across different weight configurations\n",
    "- The default weights prioritize frequency (35%) and trend (25%)\n",
    "- Risk categories (Low/Medium/High) provide actionable classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
